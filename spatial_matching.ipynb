{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e53ca9-3ac7-475d-9784-a445074f84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cartopy.crs as ccrs\n",
    "import scipy.stats as sts\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import SAM\n",
    "import float_data as flt\n",
    "\n",
    "import importlib\n",
    "importlib.reload(SAM)\n",
    "importlib.reload(flt)\n",
    "\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0acc04f-b0b2-499c-a45a-d91e00e7d0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting r1i1p1f2\n",
      "Starting r2i1p1f2\n",
      "Starting r3i1p1f2\n",
      "Starting r4i1p1f2\n",
      "Starting r5i1p1f3\n",
      "Starting r6i1p1f3\n",
      "Starting r7i1p1f3\n",
      "Starting r8i1p1f2\n",
      "Starting r9i1p1f2\n",
      "Starting r10i1p1f2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model_folder = 'model'\n",
    "n_classes = 8\n",
    "ids = ['r1i1p1f2', 'r2i1p1f2', 'r3i1p1f2', 'r4i1p1f2', 'r5i1p1f3', 'r6i1p1f3', 'r7i1p1f3', 'r8i1p1f2', 'r9i1p1f2', 'r10i1p1f2']\n",
    "mask = np.load('data/mask.npy', allow_pickle=True)\n",
    "data_classes = {}\n",
    "avg_profiles_dict = {}\n",
    "path_ref = '{}/{}/{}'.format(model_folder, ids[0], n_classes)\n",
    "with open('{}/avg.obj'.format(path_ref), 'rb') as file:\n",
    "    ref_profiles = pickle.load(file)\n",
    "    file.close()\n",
    "  \n",
    "    \n",
    "for (m_i, m_id) in enumerate(ids):\n",
    "\n",
    "    print('Starting {}'.format(m_id))\n",
    "    path_id = '{}/{}'.format(model_folder, m_id)\n",
    "    path_n = '{}/{}/{}'.format(model_folder, m_id, n_classes)\n",
    "    path_data = 'data/{}/{}'.format(m_id, n_classes)\n",
    "\n",
    "    with open('{}/pca.obj'.format(path_id), 'rb') as file:\n",
    "        pca = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    with open('{}/gmm.obj'.format(path_n), 'rb') as file:\n",
    "        gmm = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    with open('{}/avg.obj'.format(path_data), 'rb') as file:\n",
    "        avg_profiles = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    options = {'memberId' : m_id, 'raw' : True}\n",
    "    data = flt.retrieve_profiles(timeRange = slice('1970-01', '1970-12'), mask=mask, options=options)\n",
    "    data = data.chunk({'time': data.sizes['time'], 'i' : 64, 'j':64})\n",
    "    data_sampled = flt.normalise_data(data, ('i', 'j', 'time'))\n",
    "    data_trans = flt.pca_transform(data_sampled, pca)\n",
    "    \n",
    "    data_c = flt.gmm_classify(data_trans, gmm).compute()\n",
    "    data_classes[m_id] = data_c\n",
    "    continue\n",
    "    lats = data_c['lat'].values\n",
    "    lons = data_c['lon'].values\n",
    "    lev = data['lev'].values\n",
    "    times = data['time'].values\n",
    "    alpha = np.logical_not(data.isel(time=0, lev=-1).isnull().values)\n",
    "    \n",
    "\n",
    "    plt_data = data_c.values\n",
    "\n",
    "    #plt_data[plt_data == -1] = 0\n",
    "    for yr in range(np.size(plt_data, 0)):\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        ax = fig.add_subplot(projection=ccrs.SouthPolarStereo())\n",
    "        ax.pcolormesh(lons, lats, plt_data[yr, :, :], transform=ccrs.PlateCarree(), alpha=alpha, cmap='YlOrRd') #, cmap='YlOrRd'\n",
    "        ax.coastlines()\n",
    "        ax.set_title('{}, {}'.format(m_id, times[yr].astype('datetime64[M]')))\n",
    "        ax.set_facecolor((0.7, 0.7, 0.7, 1))\n",
    "        \n",
    "    \n",
    "        fig.set_size_inches(7, 7)\n",
    "        #plt.savefig('figures/anim_mm/{:03d}'.format(yr), dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(yr)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    \n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d54c2f-30c8-405a-a88c-1726d017d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c1 = data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa4c529-7f87-4582-b634-1c4f46e5532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(datac1, datac2):\n",
    "  a = [np.unique(datac2.where(datac1==k).values, return_counts=True) for k in range(n_classes)]\n",
    "  a = [(x[0][0:-1].astype('int'), x[1][0:-1]) for x in a]\n",
    "  return a\n",
    "counts = []\n",
    "for m_id in ids:\n",
    "  counts.append(f(data_classes[ids[0]], data_classes[m_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b66dc8-e98b-4360-be1f-2c04c1308572",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.zeros((len(ids), n_classes))\n",
    "for i in range(len(ids)):\n",
    "  for j in range(n_classes):\n",
    "    indices[i, j] = counts[i][j][0][np.argmax(counts[i][j][1])]\n",
    "indices = indices.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ab933b-94b7-47fe-a98c-b94b2b206f0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (k, (n, c)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43ma\u001b[49m):\n\u001b[1;32m      2\u001b[0m   plt\u001b[38;5;241m.\u001b[39mscatter(n[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], c[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "for (k, (n, c)) in enumerate(a):\n",
    "  plt.scatter(n[0:-1], c[0:-1], marker='+', label=k)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c372108d-004b-4558-bcca-bb0e4bcc66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_prob(data_c1, data_c2):\n",
    "  \n",
    "  \"\"\"\n",
    "  Replace the nan with -1\n",
    "  \"\"\"\n",
    "\n",
    "  pca_size = data_trans.sizes['pca_comp']\n",
    "  gmm_size = gmm.n_components\n",
    "  def func(arr):\n",
    "    arr_r = np.reshape(arr, (-1, pca_size))\n",
    "    \n",
    "    inds = np.isnan(arr_r) \n",
    "    arr_r[inds] = 0\n",
    "    \n",
    "    out = gmm.predict_proba(arr_r)\n",
    "    out_sizes = list(np.shape(arr))\n",
    "    out_sizes[-1] = gmm_size\n",
    "    out[inds[:, 0]] = np.nan\n",
    "    out = np.reshape(out, out_sizes)\n",
    "    return out\n",
    "\n",
    "  result = xr.apply_ufunc(\n",
    "        func,\n",
    "        data_trans,\n",
    "        input_core_dims=[['pca_comp']],\n",
    "        output_core_dims=[['k']],\n",
    "        dask='parallelized',\n",
    "        output_dtypes=('float64',),\n",
    "        vectorize=False,\n",
    "        dask_gufunc_kwargs={\n",
    "            'output_sizes' : {'k' : gmm_size}\n",
    "        }\n",
    "    )\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a56228-5e79-4cef-9cea-cdfc581db19f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_c1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mdata_c1\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(data_c2\u001b[38;5;241m==\u001b[39mk), return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m b\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_c1' is not defined"
     ]
    }
   ],
   "source": [
    "b = np.unique(data_c1.where(data_c2==k), return_counts=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890c08bc-99ea-44d2-82b3-156c20719ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4., 5., 6.],\n",
       "       [1., 0., 5., 6., 2., 3., 4.],\n",
       "       [1., 4., 0., 6., 5., 2., 3.],\n",
       "       [3., 0., 2., 5., 1., 4., 6.],\n",
       "       [2., 6., 4., 3., 0., 5., 1.],\n",
       "       [6., 2., 5., 0., 1., 4., 3.],\n",
       "       [2., 5., 0., 1., 4., 6., 3.],\n",
       "       [3., 5., 4., 2., 1., 6., 0.],\n",
       "       [0., 4., 2., 6., 3., 5., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd9ee53-f8e1-4ba2-8213-4840a41257aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting r1i1p1f2\n",
      "Starting r2i1p1f2\n",
      "Starting r3i1p1f2\n",
      "Starting r4i1p1f2\n",
      "Starting r5i1p1f3\n",
      "Starting r6i1p1f3\n",
      "Starting r7i1p1f3\n",
      "Starting r8i1p1f2\n",
      "Starting r9i1p1f2\n",
      "Starting r10i1p1f2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "avg_profiles = {}\n",
    "for m_id in ids:\n",
    "    \n",
    "    print('Starting {}'.format(m_id))\n",
    "    path_id = 'model/{}'.format(m_id)\n",
    "    path_n = 'model/{}/{}'.format(m_id, n_classes)\n",
    "    path_data = 'data/{}/{}'.format(m_id, n_classes)\n",
    "    \n",
    "\n",
    "    if os.path.exists('{}/avg.obj'.format(path_data)):\n",
    "        with open('{}/avg.obj'.format(path_data), 'rb') as file:\n",
    "            avg_profiles[m_id] = pickle.load(file)\n",
    "            file.close()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80cc6b69-c011-44cc-9756-c41f4f33e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_avg = np.array([flt.match_profiles(avg_profiles[ids[0]], avg_profiles[x]) for x in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cba526a-0780-4b97-b941-f3c7adb9fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1i1p1f2\n",
      "  Bijective spatial plots: True\n",
      "  Bijective profiles: True\n",
      "  Same assignment? True\n",
      "r2i1p1f2\n",
      "  Bijective spatial plots: False\n",
      "  Bijective profiles: False\n",
      "  Same assignment? True\n",
      "r3i1p1f2\n",
      "  Bijective spatial plots: True\n",
      "  Bijective profiles: True\n",
      "  Same assignment? True\n",
      "r4i1p1f2\n",
      "  Bijective spatial plots: False\n",
      "  Bijective profiles: False\n",
      "  Same assignment? True\n",
      "r5i1p1f3\n",
      "  Bijective spatial plots: False\n",
      "  Bijective profiles: False\n",
      "  Same assignment? True\n",
      "r6i1p1f3\n",
      "  Bijective spatial plots: False\n",
      "  Bijective profiles: False\n",
      "  Same assignment? True\n",
      "r7i1p1f3\n",
      "  Bijective spatial plots: False\n",
      "  Bijective profiles: False\n",
      "  Same assignment? False\n",
      "r8i1p1f2\n",
      "  Bijective spatial plots: True\n",
      "  Bijective profiles: True\n",
      "  Same assignment? True\n",
      "r9i1p1f2\n",
      "  Bijective spatial plots: True\n",
      "  Bijective profiles: True\n",
      "  Same assignment? True\n",
      "r10i1p1f2\n",
      "  Bijective spatial plots: True\n",
      "  Bijective profiles: True\n",
      "  Same assignment? True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (a, b, i) in zip(indices, indices_avg, ids):\n",
    "  print(i)\n",
    "  print(\"  Bijective spatial plots: {}\".format(len(a) == len(np.unique(a))))\n",
    "  print(\"  Bijective profiles: {}\".format(len(b) == len(np.unique(b))))\n",
    "  print(\"  Same assignment? {}\".format(np.all(a == b)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
