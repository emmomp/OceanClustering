{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784c0528-3181-4115-9c5e-2a4515c61f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import SAM\n",
    "import float_data as flt\n",
    "\n",
    "import importlib\n",
    "importlib.reload(SAM)\n",
    "importlib.reload(flt)\n",
    "\n",
    "from dask import delayed\n",
    "\n",
    "def f(datac1, datac2, n_classes):\n",
    "  a = [np.unique(datac2.where(datac1==k).values, return_counts=True) for k in range(n_classes)]\n",
    "  a = [(x[0][0:-1].astype('int'), x[1][0:-1]) for x in a]\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dddfa5c-79f9-4eb9-b343-6ecdd15d5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ['r1i1p1f2', 'r2i1p1f2']#, 'r3i1p1f2', 'r4i1p1f2', 'r5i1p1f3', 'r6i1p1f3', 'r7i1p1f3', 'r8i1p1f2', 'r9i1p1f2', 'r10i1p1f2']\n",
    "datas = {}\n",
    "gmm = {}\n",
    "pca = {}\n",
    "n_classes = np.array([5, 6, 7])\n",
    "model_folder = 'model'\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35115f9d-6648-4e3e-8f69-c17210493657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2i1p1f2, 7\r"
     ]
    }
   ],
   "source": [
    "for m_id in ids:\n",
    "  options = {'memberId' : m_id, 'raw' : True}\n",
    "  data = flt.retrieve_profiles(timeRange = slice('1999-01', '2000-12'), options=options)\n",
    "  datas[m_id] = data\n",
    "  \n",
    "  data = data.stack(n=('i', 'j',))\n",
    "  if mask is None:\n",
    "    mask = data.isel(time=0).dropna('n')['n'].values\n",
    "  data = data.sel(n=mask)\n",
    "  \n",
    "  data_sampled = flt.random_sample(data, 100)\n",
    "  data_normalised = flt.normalise_data(data_sampled, 'N').compute()\n",
    "  \n",
    "  # Train a PCA object\n",
    "  \n",
    "  pca[m_id] = flt.train_pca(data_normalised, 3)\n",
    "  data_pca = flt.pca_transform(data_normalised, pca[m_id]).compute()\n",
    "  \n",
    "  # Train GMM objects for each number of classes\n",
    "  gmm[m_id] = []\n",
    "  for n in n_classes:\n",
    "    gmm[m_id].append(flt.train_gmm(data_pca, n))\n",
    "    print('{}, {}'.format(m_id, n), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b83acf-bb89-4181-8188-20768b66f318",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   data_normalised \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mnormalise_data(data, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     11\u001b[0m   data_pca \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mpca_transform(data_normalised, pca[m_id])\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m---> 13\u001b[0m   avg_profiles[m_id] \u001b[38;5;241m=\u001b[39m [flt\u001b[38;5;241m.\u001b[39mavg_profiles(data, flt\u001b[38;5;241m.\u001b[39mgmm_classify(data_pca, gmm[m_id][i])\u001b[38;5;241m.\u001b[39mcompute(), n) \u001b[38;5;28;01mfor\u001b[39;00m (i, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(n_classes)]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m   data_normalised \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mnormalise_data(data, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     11\u001b[0m   data_pca \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mpca_transform(data_normalised, pca[m_id])\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m---> 13\u001b[0m   avg_profiles[m_id] \u001b[38;5;241m=\u001b[39m [\u001b[43mflt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgmm_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (i, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(n_classes)]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/OceanClustering/float_data.py:349\u001b[0m, in \u001b[0;36mavg_profiles\u001b[0;34m(data, data_classes, K)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[1;32m    348\u001b[0m   d \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwhere(data_classes\u001b[38;5;241m==\u001b[39mi)\n\u001b[0;32m--> 349\u001b[0m   d_m \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m    350\u001b[0m   d_std \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mstd((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m), skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    351\u001b[0m   out\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m : d_m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m : d_std})\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/dataarray.py:642\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    The array's data as a numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    type does not support coercion like this (e.g. cupy).\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/variable.py:512\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/variable.py:252\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/array/core.py:1686\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1686\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m   1688\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/base.py:311\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/threaded.py:81\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     79\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 81\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:497\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    496\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m    499\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:134\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueue_get\u001b[39m(q):\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_profiles = {}\n",
    "for m_id in ids:\n",
    "  \n",
    "  data = datas[m_id]\n",
    "  data = data.stack(n=('i', 'j'))\n",
    "  if mask is None:\n",
    "    mask = data.isel(time=0).dropna('n')['n'].values\n",
    "  data = data.sel(n=mask)\n",
    "  \n",
    "  data_normalised = flt.normalise_data(data, ('n', 'time')).compute()\n",
    "  data_pca = flt.pca_transform(data_normalised, pca[m_id]).compute()\n",
    "  \n",
    "  avg_profiles[m_id] = [flt.avg_profiles(data, flt.gmm_classify(data_pca, gmm[m_id][i]).compute(), n) for (i, n) in enumerate(n_classes)]\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8c8bd-0a59-4a5c-8e18-08c5134f1dff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_profiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (m, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(n_classes):\n\u001b[1;32m      2\u001b[0m   indices_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(ids), n))\n\u001b[0;32m----> 3\u001b[0m   inds \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mtemp_sort(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43mavg_profiles\u001b[49m[ids[\u001b[38;5;241m0\u001b[39m]][m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ids):\n\u001b[1;32m      5\u001b[0m       indices_avg[k, :] \u001b[38;5;241m=\u001b[39m flt\u001b[38;5;241m.\u001b[39mmatch_profiles([avg_profiles[ids[\u001b[38;5;241m0\u001b[39m]][m][j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m inds], avg_profiles[v][m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_profiles' is not defined"
     ]
    }
   ],
   "source": [
    "for (m, n) in enumerate(n_classes):\n",
    "  indices_avg = np.zeros((len(ids), n))\n",
    "  inds = flt.temp_sort(None, avg_profiles[ids[0]][m], True)\n",
    "  for (k, v) in enumerate(ids):\n",
    "      indices_avg[k, :] = flt.match_profiles([avg_profiles[ids[0]][m][j] for j in inds], avg_profiles[v][m])\n",
    "  \n",
    "  data_normalised = flt.normalise_data(datas[ids[0]], ('i', 'j', 'time'))\n",
    "  data_pca = flt.pca_transform(data_normalised, pca[ids[0]])\n",
    "  ref_classes = flt.gmm_classify(data_pca, gmm[ids[0]][m])\n",
    "  ref_classes = flt.reorder(ref_classes, inds).compute()\n",
    "  \n",
    "\n",
    "  \n",
    "  counts = []\n",
    "  for m_id in ids:\n",
    "    data_normalised = flt.normalise_data(datas[m_id], ('i', 'j', 'time'))\n",
    "    data_pca = flt.pca_transform(data_normalised, pca[m_id])\n",
    "    data_classes = flt.gmm_classify(data_pca, gmm[m_id][m]).compute()\n",
    "    counts.append(f(ref_classes, data_classes, n))\n",
    "  indices = np.zeros((len(ids), n))\n",
    "  for i in range(len(ids)):\n",
    "    for j in range(n):\n",
    "      indices[i, j] = counts[i][j][0][np.argmax(counts[i][j][1])]\n",
    "  indices = indices.astype('int')\n",
    "  \n",
    "  for (a, b, i) in zip(indices, indices_avg, ids):\n",
    "    print(i)\n",
    "    print(\"  Bijective spatial plots: {}\".format(len(a) == len(np.unique(a))))\n",
    "    print(\"  Bijective profiles: {}\".format(len(b) == len(np.unique(b))))\n",
    "    print(\"  Same assignment? {}\".format(np.all(a == b)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a4708d-b091-4ee6-a437-5d0b8ebf4e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ids)):\n\u001b[1;32m     21\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 22\u001b[0m     indices[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mcounts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[j][\u001b[38;5;241m0\u001b[39m][np\u001b[38;5;241m.\u001b[39margmax(counts[i][j][\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     23\u001b[0m indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (a, b, i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(indices, indices_avg, ids):\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for (m, n) in enumerate(n_classes):\n",
    "  indices_avg = np.zeros((len(ids), n))\n",
    "  #inds = flt.temp_sort(None, avg_profiles[ids[0]][m], True)\n",
    "  #for (k, v) in enumerate(ids):\n",
    "      #indices_avg[k, :] = flt.match_profiles([avg_profiles[ids[0]][m][j] for j in inds], avg_profiles[v][m])\n",
    "  \n",
    "  data_normalised = flt.normalise_data(datas[ids[0]], ('i', 'j', 'time'))\n",
    "  data_pca = flt.pca_transform(data_normalised, pca[ids[0]])\n",
    "  ref_classes = flt.gmm_classify(data_pca, gmm[ids[0]][m]).compute()\n",
    "  \n",
    "\n",
    "  \n",
    "  counts = {}\n",
    "  for m_id in ids:\n",
    "    data_normalised = flt.normalise_data(datas[m_id], ('i', 'j', 'time'))\n",
    "    data_pca = flt.pca_transform(data_normalised, pca[m_id])\n",
    "    data_classes = flt.gmm_classify(data_pca, gmm[m_id][m]).compute()\n",
    "    counts[m_id] = [[((data_classes.where(ref_classes==k) == j) * np.cos(data_classes['lat'] * 3.141/180)).sum(skipna=True).values for k in range(n)] for j in range(n)]\n",
    "  indices = np.zeros((len(ids), n))\n",
    "  for i in range(len(ids)):\n",
    "    for j in range(n):\n",
    "      indices[i, j] = counts[i][j][0][np.argmax(counts[i][j][1])]\n",
    "  indices = indices.astype('int')\n",
    "  \n",
    "  for (a, b, i) in zip(indices, indices_avg, ids):\n",
    "    print(i)\n",
    "    print(\"  Bijective spatial plots: {}\".format(len(a) == len(np.unique(a))))\n",
    "    print(\"  Bijective profiles: {}\".format(len(b) == len(np.unique(b))))\n",
    "    print(\"  Same assignment? {}\".format(np.all(a == b)))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb632368-d9d1-406c-b794-9c72024a98af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(counts[ids[1]]), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
